{
  "timestamp": "2026-02-20T04:02:57.981784900+00:00",
  "model_config": {
    "name": "spatialvortex-7b-dev",
    "training_epochs": 0,
    "gpu_enabled": false,
    "features": [
      "sacred_geometry",
      "vortex_cycles",
      "elp_attributes",
      "moe_routing"
    ]
  },
  "task_results": [
    {
      "task": "mmlu",
      "accuracy": 55.55555555555556,
      "num_correct": 25,
      "total": 45,
      "avg_confidence": 0.5933649,
      "time_secs": 1.0542047,
      "wrong_samples": []
    },
    {
      "task": "gsm8k",
      "accuracy": 31.11111111111111,
      "num_correct": 14,
      "total": 45,
      "avg_confidence": 0.7133917,
      "time_secs": 2.3130941,
      "wrong_samples": []
    },
    {
      "task": "hellaswag",
      "accuracy": 33.33333333333333,
      "num_correct": 15,
      "total": 45,
      "avg_confidence": 0.49127987,
      "time_secs": 3.5149754,
      "wrong_samples": []
    },
    {
      "task": "truthfulqa",
      "accuracy": 66.66666666666666,
      "num_correct": 30,
      "total": 45,
      "avg_confidence": 0.69183916,
      "time_secs": 1.9849421999999999,
      "wrong_samples": []
    },
    {
      "task": "humaneval",
      "accuracy": 100.0,
      "num_correct": 45,
      "total": 45,
      "avg_confidence": 0.9935931,
      "time_secs": 5.991964,
      "wrong_samples": []
    }
  ],
  "overall": {
    "total_correct": 129,
    "total_questions": 225,
    "overall_accuracy": 57.333333333333336,
    "total_time_secs": 18.9144755
  }
}