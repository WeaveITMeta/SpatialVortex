//! Local Training Script for SpatialVortex
//!
//! Single-machine training with:
//! - Tier 0 (7B) model configuration
//! - Unified RocksDB storage
//! - RSI-driven continuous learning
//! - CALM compression
//! - E8 quantization ready
//! - HuggingFace dataset loading
//!
//! Usage: 
//!   cargo run --bin local_train --release
//!   cargo run --bin local_train --release --features gpu  # With GPU

use aimodel::storage::{
    UnifiedStore, UnifiedStoreConfig, ModelTier, QuantizationLevel,
    StoredEmbedding,
};
use aimodel::ml::calm::{CALMEngine, CALMConfig};
use aimodel::ml::continuous_learning::{ContinuousTrainer, ContinuousLearningConfig};
use aimodel::ml::huggingface::{RSIState, RSIMetric};
use aimodel::ml::gpu_trainer::{GPUTrainer, GPUTrainConfig, beams_to_gpu_data};
use aimodel::cognition::verified_patterning::{
    VerifiedPatterningEngine, VerificationConfig, BenchmarkResult,
    ContinuousLearningConfig as VPLearningConfig,
};
use aimodel::data::{HFDatasetLoader, DatasetLoaderConfig, RealBenchmarkEvaluator};
use std::time::Instant;

fn main() {
    println!("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘         SpatialVortex Local Training - Tier 0 (7B)            â•‘");
    println!("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
    println!("â•‘  E8 Lattice + CALM Compression + RSI Continuous Learning      â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    // =========================================================================
    // Step 1: Initialize Unified Store
    // =========================================================================
    println!("ğŸ“¦ Initializing Unified Store...");
    
    let store_config = UnifiedStoreConfig {
        path: "./spatialvortex_store".into(),
        tier: ModelTier::Tier0 { name: "spatialvortex-7b-dev".to_string() },
        quantization: QuantizationLevel::INT4,
        compression: true,
        cache_size_mb: 256,
        write_buffer_mb: 64,
        bloom_filter_bits: 10,
        max_open_files: 1000,
    };

    let mut store = UnifiedStore::open(store_config).expect("Failed to open store");
    
    println!("   âœ“ Store initialized at: {:?}", store.path());
    println!("   âœ“ Model tier: {:?}", store.stats().tier.name());
    println!("   âœ“ Current stored size: {:.6} GB (calculated from actual data)", store.estimated_full_size_gb());
    println!("   âœ“ Theoretical max (tier): {:.1} GB", store.theoretical_max_size_gb());
    println!();

    // =========================================================================
    // Step 2: Initialize CALM Engine
    // =========================================================================
    println!("ğŸ§  Initializing CALM Engine...");
    
    let calm_config = CALMConfig {
        latent_dim: 256,
        chunk_size: 8,
        compression_ratio: 8,
        energy_threshold: 0.01,
        speculative_decoding: true,
        batch_size: 4,
    };
    let calm = CALMEngine::new(calm_config);
    
    println!("   âœ“ Latent dimension: 256");
    println!("   âœ“ Compression ratio: 8x");
    println!();

    // =========================================================================
    // Step 3: Initialize Continuous Learning
    // =========================================================================
    println!("ğŸ“ˆ Initializing RSI-Driven Continuous Learning...");
    
    let learning_config = ContinuousLearningConfig {
        base_learning_rate: 0.001,
        min_learning_rate: 0.0001,
        max_learning_rate: 0.01,
        batch_size: 32,
        max_epochs_per_session: 10,
        min_improvement_threshold: 0.01,
        rsi_trigger_threshold: 0.5,
        training_cooldown_ms: 5000,
        enable_synthetic_data: true,
        synthetic_data_ratio: 0.3,
        require_verification: true,
    };
    let mut trainer = ContinuousTrainer::new(learning_config);
    
    println!("   âœ“ Max epochs per session: 10");
    println!("   âœ“ Synthetic data ratio: 30%");
    println!();

    // =========================================================================
    // Step 4: Initialize Verified Patterning
    // =========================================================================
    println!("ğŸ”¬ Initializing Verified Patterning Engine...");
    
    let vp_config = VPLearningConfig::default();
    let ver_config = VerificationConfig::default();
    let mut patterning = VerifiedPatterningEngine::new(vp_config, ver_config);
    
    println!("   âœ“ Scientific verification enabled");
    println!("   âœ“ SOTA tracking: MMLU, GSM8K, ARC, HellaSwag, HumanEval");
    println!();

    // =========================================================================
    // Step 5: Load HuggingFace Datasets
    // =========================================================================
    println!("ï¿½ Loading HuggingFace Datasets...");
    let hf_start = Instant::now();
    
    let dataset_config = DatasetLoaderConfig {
        cache_dir: "./hf_cache".into(),
        max_samples: 0, // 0 = no cap, use full datasets
        streaming: true,
        shuffle: true,
        seed: 42,
    };
    let mut hf_loader = HFDatasetLoader::new(dataset_config);
    
    // Load priority datasets
    let datasets_to_load = [
        "HuggingFaceFW/fineweb-edu",  // Pre-training
        "openai/gsm8k",                // Math
        "cais/mmlu",                   // Benchmark
        "allenai/ai2_arc",             // Reasoning
        "hendrycks/math",              // Math competition
        "EleutherAI/proof-pile-2",     // Mathematical proofs
    ];
    
    for dataset_path in &datasets_to_load {
        match hf_loader.load_dataset(dataset_path) {
            Ok(count) => println!("   âœ“ {} : {} examples", dataset_path, count),
            Err(e) => println!("   âš  {} : {}", dataset_path, e),
        }
    }
    
    let hf_stats = hf_loader.stats();
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("   Total: {} examples from {} datasets", hf_stats.total_examples, hf_stats.datasets_loaded);
    println!("   By category:");
    for (cat, count) in &hf_stats.by_category {
        println!("     {:?}: {}", cat, count);
    }
    println!("   Load time: {:.2}s", hf_start.elapsed().as_secs_f64());
    println!();
    
    // Convert to training pairs
    println!("ğŸ”„ Converting to training pairs...");
    let training_data = hf_loader.get_training_pairs(64);
    println!("   âœ“ Generated {} training pairs", training_data.len());
    println!();

    // =========================================================================
    // Step 6: CALM Encoding (Compress to Latent)
    // =========================================================================
    println!("ğŸ—œï¸  CALM Encoding training data...");
    
    let mut latent_count = 0;
    for (idx, (input, _)) in training_data.iter().enumerate().take(10) {
        let latent = calm.encode(input);
        
        // Store in unified store
        store.store_calm_latent(
            &format!("latent_{}", idx),
            &latent,
            8.0, // compression ratio
            input.len(),
        ).expect("Failed to store latent");
        
        latent_count += 1;
    }
    
    println!("   âœ“ Encoded {} batches to latent space", latent_count);
    println!("   âœ“ Compression: 8x reduction");
    println!();

    // =========================================================================
    // Step 7: GPU-Accelerated Training with Optimized MatMul
    // =========================================================================
    println!("ğŸš€ Starting GPU-Accelerated Training...");
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    // Convert training data to GPU-compatible format (sample for speed)
    let gpu_data_full = beams_to_gpu_data(&training_data);
    let gpu_data: Vec<_> = gpu_data_full.into_iter().take(10000).collect(); // Sample 10K for fast training
    println!("   âœ“ Using {} training pairs (sampled for speed)", gpu_data.len());
    
    // Configure GPU trainer - balanced dimensions
    let gpu_config = GPUTrainConfig {
        batch_size: 256,        // Larger batches for speed
        learning_rate: 0.001,   // Lower LR for longer training
        epochs: 12000,          // Quick run for debug testing
        input_dim: 72,          // 8 beams * 9 digits
        hidden_dim: 768,        // Balanced hidden dimension
        output_dim: 72,
    };
    
    let mut gpu_trainer = GPUTrainer::new(gpu_config);
    
    // Run GPU training
    let train_result = gpu_trainer.train(&gpu_data);
    
    println!("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("   âœ… Training complete!");
    println!("   âœ“ Total epochs: {}", train_result.total_epochs);
    println!("   âœ“ Total samples: {}", train_result.total_samples);
    println!("   âœ“ Best loss: {:.6}", train_result.best_loss);
    println!("   âœ“ Final loss: {:.6}", train_result.final_loss);
    println!("   âœ“ Training time: {:.1}s ({:.0} samples/s)", 
             train_result.elapsed_secs, train_result.samples_per_sec);
    println!();

    // =========================================================================
    // Step 8: REAL BENCHMARK EVALUATION (from actual data files)
    // =========================================================================
    println!("ğŸ“Š Running REAL Benchmark Evaluation...");
    println!("   (Loading from benchmarks/data/ - NO hardcoded results)");
    
    // Create evaluator pointing to real benchmark data
    let benchmark_data_dir = "../benchmarks/data";
    let mut evaluator = RealBenchmarkEvaluator::new(benchmark_data_dir);
    
    // Enable verbose debug mode to see scoring breakdown
    evaluator.set_verbose_debug(true);
    
    // Train evaluator multiple iterations for better learning
    println!("   Training evaluator on {} samples (5 iterations)...", training_data.len());
    for i in 0..5 {
        evaluator.train(&training_data);
        if (i + 1) % 2 == 0 {
            println!("   âœ“ Training iteration {}/5 complete", i + 1);
        }
    }
    println!("   âœ“ Evaluator training complete");
    
    // Run all available real benchmarks
    let eval_results = evaluator.run_all_benchmarks();
    
    // Record results to storage and patterning engine
    // SOTA scores from Jan 2025 leaderboards (for comparison only)
    let sota_scores = [
        ("CommonsenseQA", 93.5),  // GPT-4
        ("SQuAD 2.0", 93.2),      // GPT-4
        ("bAbI Task 1", 100.0),   // MemN2N
        ("bAbI Task 2", 100.0),
        ("bAbI Task 3", 100.0),
        ("bAbI Task 15", 100.0),
        ("bAbI Task 16", 100.0),
    ];
    
    for result in &eval_results {
        let sota = sota_scores.iter()
            .find(|(name, _)| *name == result.benchmark_name)
            .map(|(_, s)| *s)
            .unwrap_or(100.0);
        
        let benchmark = BenchmarkResult {
            name: result.benchmark_name.clone(),
            version: "v1.0-real".to_string(),
            score: result.accuracy,
            max_score: 100.0,
            sota_score: sota,
            timestamp_ms: chrono::Utc::now().timestamp_millis() as u64,
            config_hash: "tier0-dev".to_string(),
        };
        patterning.record_benchmark(benchmark.clone());
        store.record_benchmark(benchmark).expect("Failed to record benchmark");
    }
    println!();

    // =========================================================================
    // Step 9: Store Embeddings with Sacred Geometry
    // =========================================================================
    println!("ğŸ’ Storing embeddings with sacred geometry...");
    
    for pos in 1..=9u8 {
        let embedding = StoredEmbedding {
            id: format!("emb_pos_{}", pos),
            data: vec![0u8; 256], // Placeholder for E8 quantized data
            dimension: 256,
            scale: 1.0,
            flux_position: pos,
            signal_strength: if matches!(pos, 3 | 6 | 9) { 0.95 } else { 0.80 },
            quality_boost: if matches!(pos, 3 | 6 | 9) { 1.15 } else { 1.0 },
            elp: [0.33, 0.33, 0.34], // Balanced ELP
            created_at: chrono::Utc::now().timestamp(),
        };
        store.put_embedding(embedding).expect("Failed to store embedding");
    }
    
    let sacred = store.get_sacred_embeddings();
    println!("   âœ“ Stored 9 embeddings (positions 1-9)");
    println!("   âœ“ Sacred positions (3,6,9): {} embeddings with 15% boost", sacred.len());
    println!();

    // =========================================================================
    // Step 10: Final Statistics
    // =========================================================================
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("                        FINAL STATISTICS                        ");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    
    let stats = store.stats();
    println!("   Model Tier:      {}", stats.tier.name().to_string());
    println!("   Parameters:      {}", stats.tier.param_count());
    println!("   Quantization:    {:?}", stats.quantization);
    println!("   Storage Used:    {}", stats.total_bytes_human());
    println!("   Weights:         {}", stats.weight_count);
    println!("   Embeddings:      {}", stats.embedding_count);
    println!("   Flux States:     {}", stats.flux_count);
    println!("   Latent States:   {}", stats.latent_count);
    println!("   Patterns:        {}", stats.pattern_count);
    println!("   Benchmarks:      {}", stats.benchmark_count);
    println!("   Write Ops:       {}", stats.write_count);
    println!("   Read Ops:        {}", stats.read_count);
    println!();
    
    let progress = patterning.benchmark_progress();
    println!("   SOTA Progress:");
    println!("   â”œâ”€ Avg Gap to SOTA:    {:.1}%", progress.avg_gap_to_sota);
    println!("   â””â”€ Avg SOTA %:         {:.1}%", progress.avg_sota_percentage);
    println!();
    
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!("   âœ… Local training complete! Ready for scaling.");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
}
