//! Response Quality Demo
//!
//! Demonstrates the improved chat response system that addresses:
//! - Context loss (returning code for greetings)
//! - Over-engineered responses (frameworks for simple questions)
//! - Information overload (massive walls of text)
//! - Formatting abuse (excessive markdown)

use spatial_vortex::core::sacred_geometry::{
    FluxMatrixEngine, MatrixGuidedInference, ResponseMode,
};

fn main() {
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘        Response Quality Improvement Demo                â•‘");
    println!("â•‘                                                          â•‘");
    println!("â•‘  Adaptive Modes Â· Clean Formatting Â· Context Awareness  â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    // Create inference system
    let flux_engine = FluxMatrixEngine::new();
    let inference = MatrixGuidedInference::new(flux_engine);
    
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    // Demo 1: Greeting (should be CONCISE, not code)
    demo_greeting(&inference);
    
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    // Demo 2: Simplification request (should be SHORT)
    demo_simplification(&inference);
    
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    // Demo 3: Trade-offs question (should be BALANCED, not essay)
    demo_balanced_response(&inference);
    
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    // Demo 4: Complex query (can be DETAILED)
    demo_detailed_response(&inference);
    
    println!("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
    println!("â•‘                   Demo Complete! âœ…                      â•‘");
    println!("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    println!("ğŸ¯ Key Improvements Demonstrated:");
    println!("   âœ“ Greetings get friendly replies (not code!)");
    println!("   âœ“ Simple requests get concise answers");
    println!("   âœ“ Balanced responses for normal questions");
    println!("   âœ“ Detailed only when complexity warrants it");
    println!("   âœ“ Clean formatting throughout");
    println!("   âœ“ No meta-commentary or 'As Vortex, I...' phrases\n");
    
    println!("   Natural conversation beats overwhelming documentation! ğŸŒ€\n");
}

fn demo_greeting(inference: &MatrixGuidedInference) {
    println!("ğŸ“Š Demo 1: Greeting Detection");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    let query = "How do you do?";
    println!("User Query: \"{}\"\n", query);
    
    match inference.build_adaptive_prompt(query, "general") {
        Ok((prompt, mode)) => {
            println!("âœ… Detected Mode: {:?}", mode);
            println!("\nğŸ“ Generated System Prompt:\n");
            println!("{}", prompt);
            
            println!("\nğŸ’¡ What This Prevents:");
            println!("   âŒ BEFORE: Returns Python NLTK sentiment analysis code");
            println!("   âœ… AFTER: Returns friendly greeting (1-2 sentences)");
        }
        Err(e) => println!("âŒ Error: {}", e),
    }
}

fn demo_simplification(inference: &MatrixGuidedInference) {
    println!("ğŸ“Š Demo 2: Simplification Request");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    let query = "Can you explain this in simpler terms?";
    println!("User Query: \"{}\"\n", query);
    
    match inference.build_adaptive_prompt(query, "cognition") {
        Ok((prompt, mode)) => {
            println!("âœ… Detected Mode: {:?}", mode);
            println!("\nğŸ“ Key Instructions from Prompt:\n");
            
            // Extract key parts
            if prompt.contains("CONCISE") {
                println!("   â€¢ Response mode: CONCISE");
                println!("   â€¢ Maximum: 2-3 sentences");
                println!("   â€¢ Direct answer only");
                println!("   â€¢ No lengthy explanations");
            }
            
            println!("\nğŸ’¡ What This Prevents:");
            println!("   âŒ BEFORE: 'Simplifying Complex Concepts' framework with");
            println!("             multi-step methodology, pipes, task lists");
            println!("   âœ… AFTER: 2-3 sentence direct answer");
        }
        Err(e) => println!("âŒ Error: {}", e),
    }
}

fn demo_balanced_response(inference: &MatrixGuidedInference) {
    println!("ğŸ“Š Demo 3: Trade-Offs Question (Balanced)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    let query = "What are the trade-offs?";
    println!("User Query: \"{}\"\n", query);
    
    match inference.build_adaptive_prompt(query, "cognition") {
        Ok((prompt, mode)) => {
            println!("âœ… Detected Mode: {:?}", mode);
            println!("\nğŸ“ Key Instructions from Prompt:\n");
            
            if prompt.contains("BALANCED") {
                println!("   â€¢ Response mode: BALANCED");
                println!("   â€¢ Length: 2-4 short paragraphs maximum");
                println!("   â€¢ Include 1 example if helpful");
                println!("   â€¢ Bullet points ONLY for 3+ distinct items");
                println!("   â€¢ No === headers or excessive formatting");
            }
            
            println!("\nğŸ’¡ What This Prevents:");
            println!("   âŒ BEFORE: 600-word essay with:");
            println!("             === headers, ### subheaders, tables,");
            println!("             multiple examples, overwhelming detail");
            println!("   âœ… AFTER: 150-200 word clear explanation");
        }
        Err(e) => println!("âŒ Error: {}", e),
    }
}

fn demo_detailed_response(inference: &MatrixGuidedInference) {
    println!("ğŸ“Š Demo 4: Complex Technical Query (Detailed OK)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    
    let query = "Explain the mathematical foundations of vortex mathematics \
                 including the doubling sequence, sacred positions 3-6-9, \
                 and how digital root reduction creates stable attractors \
                 in the flux pattern.";
    
    println!("User Query: \"{}...\" (complex technical)\n", &query[..80]);
    
    match inference.build_adaptive_prompt(query, "mathematics") {
        Ok((prompt, mode)) => {
            println!("âœ… Detected Mode: {:?}", mode);
            println!("\nğŸ“ Key Instructions from Prompt:\n");
            
            if prompt.contains("DETAILED") {
                println!("   â€¢ Response mode: DETAILED");
                println!("   â€¢ Provide comprehensive explanation");
                println!("   â€¢ Include 2-3 concrete examples");
                println!("   â€¢ Break into clear sections (max 3)");
                println!("   â€¢ Still conversational, not academic");
            }
            
            println!("\nğŸ’¡ When Detailed Mode is Appropriate:");
            println!("   âœ“ Complex technical question with multiple parts");
            println!("   âœ“ User explicitly asks for comprehensive answer");
            println!("   âœ“ Topic has high complexity (many associations)");
            println!("   âœ“ Still maintains conversational tone");
        }
        Err(e) => println!("âŒ Error: {}", e),
    }
}
