//! Background Learning Service for Consciousness Simulation
//!
//! Continuously learns and improves in the background without user interaction.
//! Integrates with:
//! - Predictive Processor (refine world model)
//! - Meta-Cognitive Monitor (optimize pattern detection)
//! - RAG System (ingest new knowledge)
//! - Confidence Lake (review high-value memories)

use super::{MetaCognitiveMonitor, PredictiveProcessor, IntegratedInformationCalculator};
use anyhow::Result;
use std::sync::Arc;
use std::path::PathBuf;
use tokio::sync::RwLock;
use tokio::time::{Duration, interval};

#[cfg(feature = "rag")]
use crate::rag::ContinuousLearner;

#[cfg(feature = "lake")]
use crate::storage::confidence_lake::ConfidenceLake;

/// Background learning service that runs continuously
pub struct BackgroundLearner {
    /// Meta-cognitive monitor to improve
    meta_monitor: Arc<RwLock<MetaCognitiveMonitor>>,
    
    /// Predictive processor to refine
    predictor: Arc<RwLock<PredictiveProcessor>>,
    
    /// Œ¶ calculator to optimize
    phi_calculator: Arc<RwLock<IntegratedInformationCalculator>>,
    
    /// RAG continuous learner (optional)
    #[cfg(feature = "rag")]
    rag_learner: Option<Arc<ContinuousLearner>>,
    
    /// Confidence Lake for pattern review (optional)
    #[cfg(feature = "lake")]
    confidence_lake: Option<Arc<RwLock<ConfidenceLake>>>,
    
    /// Learning interval
    learning_interval: Duration,
    
    /// Configuration
    config: BackgroundLearningConfig,
    
    /// Active learning enabled
    active: Arc<RwLock<bool>>,
    
    /// Learning statistics
    stats: Arc<RwLock<LearningStats>>,
}

/// Statistics about background learning
#[derive(Debug, Clone, Default, serde::Serialize, serde::Deserialize)]
pub struct LearningStats {
    /// Total learning cycles completed
    pub cycles_completed: usize,
    
    /// Patterns refined
    pub patterns_refined: usize,
    
    /// World model updates
    pub model_updates: usize,
    
    /// Knowledge ingested (bytes)
    pub knowledge_ingested: usize,
    
    /// Last learning time
    pub last_learning: Option<std::time::SystemTime>,
    
    /// Average improvement per cycle
    pub avg_improvement: f64,
}

impl BackgroundLearner {
    /// Create new background learner
    pub fn new(
        meta_monitor: Arc<RwLock<MetaCognitiveMonitor>>,
        predictor: Arc<RwLock<PredictiveProcessor>>,
        phi_calculator: Arc<RwLock<IntegratedInformationCalculator>>,
    ) -> Self {
        Self {
            meta_monitor,
            predictor,
            phi_calculator,
            #[cfg(feature = "rag")]
            rag_learner: None,
            #[cfg(feature = "lake")]
            confidence_lake: None,
            learning_interval: Duration::from_secs(300), // 5 minutes default
            config: BackgroundLearningConfig::default(),
            active: Arc::new(RwLock::new(false)),
            stats: Arc::new(RwLock::new(LearningStats::default())),
        }
    }
    
    /// Enable RAG knowledge ingestion
    #[cfg(feature = "rag")]
    pub fn with_rag_learner(mut self, learner: Arc<ContinuousLearner>) -> Self {
        self.rag_learner = Some(learner);
        self
    }
    
    /// Enable Confidence Lake pattern review
    #[cfg(feature = "lake")]
    pub fn with_confidence_lake(mut self, lake: Arc<RwLock<ConfidenceLake>>) -> Self {
        self.confidence_lake = Some(lake);
        self
    }
    
    /// Set learning configuration
    pub fn with_config(mut self, config: BackgroundLearningConfig) -> Self {
        self.learning_interval = config.learning_interval;
        self.config = config;
        self
    }
    
    /// Start background learning (non-blocking)
    pub async fn start(&self) -> Result<()> {
        let mut active = self.active.write().await;
        *active = true;
        drop(active);
        
        println!("üß† Background learning started (interval: {:?})", self.learning_interval);
        
        // Spawn background task
        let meta_monitor = self.meta_monitor.clone();
        let predictor = self.predictor.clone();
        let phi_calculator = self.phi_calculator.clone();
        #[cfg(feature = "rag")]
        let rag_learner = self.rag_learner.clone();
        #[cfg(feature = "lake")]
        let confidence_lake = self.confidence_lake.clone();
        let config = self.config.clone();
        let learning_interval = self.learning_interval;
        let active_flag = self.active.clone();
        let stats = self.stats.clone();
        
        tokio::spawn(async move {
            let mut interval_timer = interval(learning_interval);
            
            loop {
                interval_timer.tick().await;
                
                // Check if still active
                let is_active = *active_flag.read().await;
                if !is_active {
                    println!("üõë Background learning stopped");
                    break;
                }
                
                // Perform learning cycle
                if let Err(e) = Self::learning_cycle(
                    &meta_monitor,
                    &predictor,
                    &phi_calculator,
                    #[cfg(feature = "rag")]
                    &rag_learner,
                    #[cfg(feature = "lake")]
                    &confidence_lake,
                    &config,
                    &stats,
                ).await {
                    eprintln!("‚ùå Background learning error: {}", e);
                }
            }
        });
        
        Ok(())
    }
    
    /// Stop background learning
    pub async fn stop(&self) {
        let mut active = self.active.write().await;
        *active = false;
    }
    
    /// Single learning cycle
    async fn learning_cycle(
        meta_monitor: &Arc<RwLock<MetaCognitiveMonitor>>,
        predictor: &Arc<RwLock<PredictiveProcessor>>,
        phi_calculator: &Arc<RwLock<IntegratedInformationCalculator>>,
        #[cfg(feature = "rag")]
        rag_learner: &Option<Arc<ContinuousLearner>>,
        #[cfg(feature = "lake")]
        confidence_lake: &Option<Arc<RwLock<ConfidenceLake>>>,
        config: &BackgroundLearningConfig,
        stats: &Arc<RwLock<LearningStats>>,
    ) -> Result<()> {
        let start_time = std::time::Instant::now();
        
        println!("üîÑ Background learning cycle starting...");
        
        // 1. Analyze meta-cognitive patterns
        let patterns_refined = {
            let monitor = meta_monitor.read().await;
            // TODO: Analyze historical patterns and optimize detection thresholds
            monitor.patterns().len()
        };
        
        // 2. Refine predictive model
        let model_updates = {
            let pred = predictor.write().await;
            // The world model is already being updated during think()
            // But we can optimize learning rate based on recent performance
            let accuracy = pred.prediction_accuracy();
            
            // Adjust learning rate based on accuracy
            if accuracy < 0.5 {
                // Low accuracy = learn faster
                // TODO: Add learning_rate field to PredictiveProcessor
                1
            } else if accuracy > 0.9 {
                // High accuracy = learn slower (avoid overfitting)
                0
            } else {
                0
            }
        };
        
        // 3. Optimize Œ¶ calculation
        {
            let phi_calc = phi_calculator.write().await;
            // Prune old thoughts if network getting too large
            if phi_calc.network_size() > 8 {
                // Network auto-prunes at 10, but we can be proactive
                // Already handled by IntegratedInformationCalculator
            }
        }
        
        // 4. Ingest new knowledge from RAG sources
        let knowledge_ingested = {
            #[cfg(feature = "rag")]
            {
                if config.enable_rag_ingestion {
                    if let Some(ref _learner) = rag_learner {
                        // RAG learner runs in its own background task
                        // Just check if it's active
                        println!("   üìö RAG ingestion: Active");
                        1 // Indicate RAG is working
                    } else {
                        println!("   üìö RAG ingestion: Not configured");
                        0
                    }
                } else {
                    0
                }
            }
            
            #[cfg(not(feature = "rag"))]
            {
                let _ = config; // Suppress unused warning
                0
            }
        };
        
        // 5. Review Confidence Lake for patterns
        let patterns_from_lake = {
            #[cfg(feature = "lake")]
            {
                if config.enable_lake_review {
                    if let Some(ref lake) = confidence_lake {
                        let lake_guard = lake.read().await;
                        let count = lake_guard.len();
                        let used = lake_guard.used_space();
                        println!("   üíé Confidence Lake: {} entries ({} bytes)", count, used);
                        
                        // Get recent high-value patterns
                        let timestamps = lake_guard.list_timestamps();
                        let recent_count = timestamps.iter()
                            .rev()
                            .take(10)
                            .count();
                        
                        println!("   üíé Reviewing {} recent patterns", recent_count);
                        
                        // TODO: Extract patterns and inform predictive model
                        // For now, just count them
                        recent_count
                    } else {
                        println!("   üíé Confidence Lake: Not configured");
                        0
                    }
                } else {
                    0
                }
            }
            
            #[cfg(not(feature = "lake"))]
            {
                0
            }
        };
        
        // Update statistics
        let elapsed = start_time.elapsed();
        let mut stats_guard = stats.write().await;
        stats_guard.cycles_completed += 1;
        stats_guard.patterns_refined += patterns_refined;
        stats_guard.model_updates += model_updates;
        stats_guard.knowledge_ingested += knowledge_ingested;
        stats_guard.last_learning = Some(std::time::SystemTime::now());
        
        println!("‚úÖ Learning cycle complete ({:.2}s)", elapsed.as_secs_f64());
        println!("   Patterns: {}, Model updates: {}, Knowledge: {}, Lake patterns: {}", 
            patterns_refined, model_updates, knowledge_ingested, patterns_from_lake);
        
        Ok(())
    }
    
    /// Get learning statistics
    pub async fn stats(&self) -> LearningStats {
        self.stats.read().await.clone()
    }
    
    /// Check if background learning is active
    pub async fn is_active(&self) -> bool {
        *self.active.read().await
    }
    
    /// Set learning interval
    pub async fn set_interval(&mut self, interval: Duration) {
        self.learning_interval = interval;
    }
}

/// Configuration for background learning
#[derive(Debug, Clone)]
pub struct BackgroundLearningConfig {
    /// How often to run learning cycles
    pub learning_interval: Duration,
    
    /// Enable RAG knowledge ingestion
    pub enable_rag_ingestion: bool,
    
    /// Enable Confidence Lake review
    pub enable_lake_review: bool,
    
    /// RAG data source directories (if RAG enabled)
    #[cfg(feature = "rag")]
    pub rag_sources: Vec<PathBuf>,
    
    /// Confidence Lake file path (if Lake enabled)
    #[cfg(feature = "lake")]
    pub lake_path: Option<PathBuf>,
    
    /// Minimum prediction accuracy before adjusting learning rate
    pub min_accuracy_threshold: f64,
    
    /// Maximum network size before aggressive pruning
    pub max_network_size: usize,
    
    /// Minimum signal strength for Confidence Lake storage
    pub min_confidence: f64,
}

impl Default for BackgroundLearningConfig {
    fn default() -> Self {
        Self {
            learning_interval: Duration::from_secs(300), // 5 minutes
            enable_rag_ingestion: true,
            enable_lake_review: true,
            #[cfg(feature = "rag")]
            rag_sources: vec![],
            #[cfg(feature = "lake")]
            lake_path: None,
            min_accuracy_threshold: 0.5,
            max_network_size: 8,
            min_confidence: 0.6, // Only store high-quality patterns
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_background_learner_creation() {
        let meta_monitor = Arc::new(RwLock::new(MetaCognitiveMonitor::new()));
        let predictor = Arc::new(RwLock::new(PredictiveProcessor::new()));
        let phi_calc = Arc::new(RwLock::new(IntegratedInformationCalculator::new()));
        
        let learner = BackgroundLearner::new(meta_monitor, predictor, phi_calc);
        
        assert!(!learner.is_active().await);
    }
    
    #[tokio::test]
    async fn test_start_stop() {
        let meta_monitor = Arc::new(RwLock::new(MetaCognitiveMonitor::new()));
        let predictor = Arc::new(RwLock::new(PredictiveProcessor::new()));
        let phi_calc = Arc::new(RwLock::new(IntegratedInformationCalculator::new()));
        
        let learner = BackgroundLearner::new(meta_monitor, predictor, phi_calc);
        
        learner.start().await.unwrap();
        assert!(learner.is_active().await);
        
        learner.stop().await;
        // Give it a moment to stop
        tokio::time::sleep(Duration::from_millis(100)).await;
        assert!(!learner.is_active().await);
    }
}
