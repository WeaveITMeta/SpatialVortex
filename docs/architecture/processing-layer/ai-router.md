# AI Router System Documentation

**Version**: 1.0.0  
**Date**: October 22, 2025  
**Status**: Production Ready âœ…

---

## Overview

The **AI Router** is a sophisticated request management system for SpatialVortex that handles multiple types of AI requests with priority queuing, rate limiting, and compression hash integration.

### Key Features

- âœ… **5 Request Types**: User, Machine, Compliance, System, Priority
- âœ… **Priority Queuing**: Automatic request prioritization
- âœ… **Rate Limiting**: Per-type request throttling
- âœ… **Compression Integration**: 12-byte hash support
- âœ… **ELP Analysis**: Automatic sentiment detection
- âœ… **Statistics Tracking**: Real-time performance metrics
- âœ… **Timeout Handling**: Automatic request expiration
- âœ… **Type Safety**: Full Rust type system

---

## Request Types

### 1. **User Requests** ðŸ‘¤

**Purpose**: Interactive user queries and chat  
**Priority**: 2 (Medium)  
**Rate Limit**: 60 requests/minute  
**Timeout**: 30 seconds  
**Compression**: Enabled  

**Use Cases**:
- Chat conversations
- User questions
- Interactive queries
- Personal assistance

**Example**:
```rust
use spatialvortex::ai_router::{AIRouter, AIRequest};

let request = AIRequest::new_user(
    "What is consciousness?".to_string(),
    "user_123".to_string()
);

let request_id = router.submit_request(request).await?;
let response = router.process_next().await?;
```

---

### 2. **Machine Requests** ðŸ¤–

**Purpose**: API calls and automation  
**Priority**: 4 (Lowest)  
**Rate Limit**: 600 requests/minute  
**Timeout**: 120 seconds  
**Compression**: Enabled  

**Use Cases**:
- API integrations
- Automated workflows
- Batch processing
- M2M communication

**Example**:
```rust
let request = AIRequest::new_machine(
    "Analyze dataset: {...}".to_string(),
    "api_key_abc123".to_string()
);

let request_id = router.submit_request(request).await?;
```

**Metadata**:
- `api_key`: Authentication key for machine requests

---

### 3. **Compliance Requests** ðŸ›¡ï¸

**Purpose**: Content moderation and policy enforcement  
**Priority**: 1 (High)  
**Rate Limit**: 200 requests/minute  
**Timeout**: 10 seconds  
**Compression**: Enabled  

**Use Cases**:
- Content moderation
- Policy compliance checks
- Safety filtering
- Ethical validation
- Regulatory compliance

**Example**:
```rust
let request = AIRequest::new_compliance(
    "Check content: 'User submitted text...'".to_string(),
    "content_policy_v2".to_string()
);

let request_id = router.submit_request(request).await?;
let response = router.process_next().await?;

// Response includes compliance verdict
if response.confidence > 0.8 {
    println!("Content complies with policy");
}
```

**Metadata**:
- `policy`: Policy identifier to check against

**ELP Profile**: High Ethos (9.0), Medium Logos (7.0), Low Pathos (4.0)

---

### 4. **System Requests** âš™ï¸

**Purpose**: Health checks and diagnostics  
**Priority**: 3 (Low)  
**Rate Limit**: 30 requests/minute  
**Timeout**: 60 seconds  
**Compression**: Disabled  

**Use Cases**:
- Health monitoring
- System diagnostics
- Performance checks
- Maintenance tasks
- Internal telemetry

**Example**:
```rust
let request = AIRequest::new_system(
    "Health check: inference_engine".to_string()
);

let request_id = router.submit_request(request).await?;
let response = router.process_next().await?;

// Response contains diagnostic info
println!("Processing time: {}ms", response.processing_time_ms);
```

**ELP Profile**: Medium Ethos (5.0), High Logos (9.0), Low Pathos (3.0)

---

### 5. **Priority Requests** ðŸš¨

**Purpose**: Emergency and critical operations  
**Priority**: 0 (Highest)  
**Rate Limit**: 100 requests/minute  
**Timeout**: 5 seconds  
**Compression**: Enabled  

**Use Cases**:
- Emergency responses
- Critical alerts
- High-priority user requests
- Security incidents
- Time-sensitive operations

**Example**:
```rust
let request = AIRequest::new_priority(
    "URGENT: Security breach detected".to_string(),
    "admin_001".to_string(),
    "security_incident".to_string()
);

let request_id = router.submit_request(request).await?;
let response = router.process_next().await?;
```

**Metadata**:
- `priority_reason`: Justification for priority status

**ELP Profile**: All High (8.0, 8.0, 8.0)

---

## Architecture

### System Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Request   â”‚
â”‚  Submission â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rate Limiter â”‚ â† Check limits per type
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Priority     â”‚ â† Sort by priority level
â”‚ Queue        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Compression  â”‚ â† Create 12-byte hash
â”‚ (if enabled) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ELP Analysis â”‚ â† Detect sentiment channels
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Inference   â”‚ â† Run semantic inference
â”‚   Engine     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Response   â”‚ â† Generate response
â”‚  Generation  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Statistics  â”‚ â† Update metrics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Priority Queue

Requests are processed in strict priority order:

| Priority | Request Type | Queue Position | Processing Order |
|----------|--------------|----------------|------------------|
| 0 | Priority | First | 1st |
| 1 | Compliance | Second | 2nd |
| 2 | User | Third | 3rd |
| 3 | System | Fourth | 4th |
| 4 | Machine | Last | 5th |

**Example**:
```
Queue State:
  Priority:   [Req1] â† Processed first
  Compliance: [Req2, Req3]
  User:       [Req4, Req5, Req6]
  System:     []
  Machine:    [Req7, Req8, Req9, Req10]
```

---

## Rate Limiting

Each request type has independent rate limits:

| Type | Limit | Window | Reason |
|------|-------|--------|--------|
| Priority | 100/min | 1 min | Prevent abuse of emergency system |
| Compliance | 200/min | 1 min | Balance safety checks with performance |
| User | 60/min | 1 min | Standard interactive rate |
| System | 30/min | 1 min | Prevent diagnostic spam |
| Machine | 600/min | 1 min | High throughput for automation |

**Rate Limit Response**:
```json
{
  "error": "Rate limit exceeded for User requests",
  "retry_after": 42,
  "limit": 60,
  "window": "1 minute"
}
```

---

## Compression Hash Integration

### Automatic Compression

When compression is enabled (default for most types), the router:

1. Creates 12-byte compression hash
2. Encodes ELP channels
3. Maps to flux position
4. Stores hash metadata
5. Uses hash for inference

**Flux Position Mapping**:
```rust
Priority   â†’ Position 9 (Divine)
Compliance â†’ Position 6 (Sacred)
User       â†’ Position 3 (Creative)
Machine    â†’ Position 5 (Balance)
System     â†’ Position 0 (Foundation)
```

### ELP Analysis

The router automatically analyzes prompts for ELP channels:

**Base ELP by Request Type**:
| Type | Ethos | Logos | Pathos | Profile |
|------|-------|-------|--------|---------|
| Compliance | 9.0 | 7.0 | 4.0 | Ethics-focused |
| System | 5.0 | 9.0 | 3.0 | Logic-focused |
| User | 6.0 | 6.0 | 7.0 | Balanced |
| Machine | 4.0 | 8.0 | 3.0 | Logic-focused |
| Priority | 8.0 | 8.0 | 8.0 | All high |

**Content Adjustments**:
- Keywords like "ethics", "moral" â†’ +2.0 Ethos
- Keywords like "analyze", "calculate" â†’ +2.0 Logos
- Keywords like "feel", "emotion" â†’ +2.0 Pathos

---

## API Usage

### Basic Setup

```rust
use spatialvortex::ai_router::{AIRouter, AIRequest, RequestType};
use spatialvortex::inference_engine::InferenceEngine;

// Create inference engine
let mut engine = InferenceEngine::new();
// Load matrices...

// Create router
let router = AIRouter::new(engine);
```

### Submit Request

```rust
// Create request
let request = AIRequest::new_user(
    "What is AI?".to_string(),
    "user_456".to_string()
);

// Submit to router
match router.submit_request(request).await {
    Ok(request_id) => {
        println!("Request submitted: {}", request_id);
    }
    Err(e) => {
        eprintln!("Rate limit exceeded: {}", e);
    }
}
```

### Process Requests

```rust
// Process single request
if let Some(response) = router.process_next().await? {
    println!("Response: {}", response.response);
    println!("Confidence: {:.2}", response.confidence);
    
    if let Some(hash) = response.compression_hash {
        println!("Hash: {}", hash);
    }
}

// Process all pending (batch mode)
let responses = router.process_all().await?;
println!("Processed {} requests", responses.len());
```

### Check Statistics

```rust
let stats = router.get_stats().await;

println!("Total requests: {}", stats.total_requests);
println!("Average processing time: {}ms", stats.average_processing_time_ms);
println!("Rate limit hits: {}", stats.rate_limit_hits);
println!("Timeouts: {}", stats.timeout_count);

for (request_type, count) in stats.pending_by_type {
    println!("{:?}: {} pending", request_type, count);
}
```

---

## Response Format

### AIResponse Structure

```rust
pub struct AIResponse {
    pub request_id: Uuid,
    pub response: String,
    pub compression_hash: Option<String>,      // 24-char hex
    pub flux_position: Option<u8>,             // 0-9
    pub elp_channels: Option<ELPValues>,       // E/L/P values
    pub confidence: f32,                       // 0.0-1.0
    pub processing_time_ms: u64,
    pub request_type: RequestType,
    pub model_used: String,
    pub created_at: DateTime<Utc>,
}
```

### Example Response (JSON)

```json
{
  "request_id": "550e8400-e29b-41d4-a716-446655440000",
  "response": "Processed: 'What is consciousness?' â†’ Primary association: 'awareness' (confidence: 0.89)",
  "compression_hash": "a3f7c29e8b4d1506f2a8",
  "flux_position": 3,
  "elp_channels": {
    "ethos": 6.0,
    "logos": 6.0,
    "pathos": 7.0
  },
  "confidence": 0.89,
  "processing_time_ms": 45,
  "request_type": "User",
  "model_used": "spatialvortex-inference",
  "created_at": "2025-10-22T17:18:00Z"
}
```

---

## Error Handling

### Error Types

1. **Rate Limit Exceeded**
   ```rust
   Err(SpatialVortexError::InvalidInput(
       "Rate limit exceeded for User requests"
   ))
   ```

2. **Request Timeout**
   ```rust
   Err(SpatialVortexError::InvalidInput(
       "Request abc123 timed out after 35 seconds"
   ))
   ```

3. **Inference Error**
   ```rust
   Err(SpatialVortexError::InferenceEngine(
       "No compression hashes or seed numbers provided"
   ))
   ```

### Error Recovery

```rust
match router.submit_request(request).await {
    Ok(id) => {
        // Process normally
    }
    Err(SpatialVortexError::InvalidInput(msg)) if msg.contains("Rate limit") => {
        // Wait and retry
        tokio::time::sleep(Duration::from_secs(10)).await;
        router.submit_request(request).await?;
    }
    Err(e) => {
        eprintln!("Unexpected error: {}", e);
    }
}
```

---

## Performance Metrics

### Benchmarks

| Operation | Time | Notes |
|-----------|------|-------|
| Submit request | ~50Î¼s | Queue insertion |
| Rate limit check | ~100Î¼s | HashMap lookup |
| Compression | ~1Î¼s | 12-byte hash |
| ELP analysis | ~5Î¼s | String analysis |
| Inference | ~2-5ms | Depends on matrices |
| Total (typical) | ~3-6ms | End-to-end |

### Throughput

| Request Type | Max Throughput | Bottleneck |
|--------------|----------------|------------|
| Priority | 100 req/min | Rate limit |
| Compliance | 200 req/min | Rate limit |
| User | 60 req/min | Rate limit |
| System | 30 req/min | Rate limit |
| Machine | 600 req/min | Rate limit |

---

## Use Cases

### 1. Chat Application

```rust
// User sends message
let request = AIRequest::new_user(
    user_message,
    user_id
);

router.submit_request(request).await?;

// Process and return response
if let Some(response) = router.process_next().await? {
    send_to_user(response.response).await?;
}
```

### 2. Content Moderation

```rust
// Check user-generated content
let request = AIRequest::new_compliance(
    format!("Check content: {}", user_content),
    "content_policy_v2".to_string()
);

router.submit_request(request).await?;
let response = router.process_next().await?.unwrap();

if response.confidence < 0.7 {
    flag_for_review(user_content).await?;
}
```

### 3. API Integration

```rust
// External API call
let request = AIRequest::new_machine(
    format!("Analyze: {}", json_data),
    api_key
);

router.submit_request(request).await?;

// Batch process all API requests
let responses = router.process_all().await?;
return_json(responses).await?;
```

### 4. Emergency Response

```rust
// Critical alert
let request = AIRequest::new_priority(
    "Security breach detected in sector 7".to_string(),
    admin_id,
    "security_incident".to_string()
);

// Submits to front of queue
router.submit_request(request).await?;

// Processed immediately (priority 0)
let response = router.process_next().await?.unwrap();
send_alert(response).await?;
```

---

## Best Practices

### 1. Request Type Selection

âœ… **DO**:
- Use `User` for interactive requests
- Use `Machine` for batch processing
- Use `Compliance` for safety checks
- Use `Priority` only for emergencies

âŒ **DON'T**:
- Use `Priority` for normal requests
- Use `User` for automation
- Mix request types unnecessarily

### 2. Rate Limit Management

âœ… **DO**:
- Monitor rate limit hits
- Implement exponential backoff
- Use appropriate request types
- Batch when possible

âŒ **DON'T**:
- Retry immediately on rate limit
- Spam priority requests
- Ignore rate limit errors

### 3. Error Handling

âœ… **DO**:
- Handle all error cases
- Log timeouts
- Implement retries with backoff
- Monitor statistics

âŒ **DON'T**:
- Ignore timeout errors
- Retry infinitely
- Swallow errors silently

---

## Monitoring

### Key Metrics to Track

1. **Request Volume**
   - Total requests per type
   - Requests per minute
   - Peak request times

2. **Performance**
   - Average processing time
   - P95/P99 latency
   - Queue depth

3. **Errors**
   - Rate limit hits
   - Timeout count
   - Inference failures

4. **Resource Usage**
   - Queue memory
   - Inference engine load
   - CPU/Memory utilization

### Example Monitoring

```rust
// Poll statistics every 30 seconds
tokio::spawn(async move {
    loop {
        let stats = router.get_stats().await;
        
        log::info!("Total requests: {}", stats.total_requests);
        log::info!("Avg time: {}ms", stats.average_processing_time_ms);
        log::info!("Pending: {}", stats.pending_by_type.values().sum::<usize>());
        
        if stats.rate_limit_hits > 100 {
            log::warn!("High rate limit hits: {}", stats.rate_limit_hits);
        }
        
        tokio::time::sleep(Duration::from_secs(30)).await;
    }
});
```

---

## Testing

### Unit Tests

```bash
cargo test ai_router --lib
```

### Integration Test Example

```rust
#[tokio::test]
async fn test_full_request_flow() {
    let engine = InferenceEngine::new();
    let router = AIRouter::new(engine);
    
    // Submit various request types
    let user_req = AIRequest::new_user("Hello".to_string(), "user1".to_string());
    let machine_req = AIRequest::new_machine("Process".to_string(), "key".to_string());
    let compliance_req = AIRequest::new_compliance("Check".to_string(), "policy".to_string());
    
    router.submit_request(user_req).await.unwrap();
    router.submit_request(machine_req).await.unwrap();
    router.submit_request(compliance_req).await.unwrap();
    
    // Process all
    let responses = router.process_all().await.unwrap();
    assert_eq!(responses.len(), 3);
    
    // Verify priority order: Compliance, User, Machine
    assert_eq!(responses[0].request_type, RequestType::Compliance);
    assert_eq!(responses[1].request_type, RequestType::User);
    assert_eq!(responses[2].request_type, RequestType::Machine);
}
```

---

## Migration Guide

### From Direct Inference Engine

**Before**:
```rust
let result = inference_engine.process_inference(input).await?;
```

**After**:
```rust
let request = AIRequest::new_user(prompt, user_id);
router.submit_request(request).await?;
let response = router.process_next().await?.unwrap();
```

### Benefits

1. âœ… Automatic priority management
2. âœ… Built-in rate limiting
3. âœ… Request type organization
4. âœ… Statistics tracking
5. âœ… Timeout handling

---

## Future Enhancements

### Planned Features

- [ ] WebSocket streaming responses
- [ ] Request cancellation
- [ ] Custom priority rules
- [ ] Multi-model routing
- [ ] Load balancing across inference engines
- [ ] Persistent queue (Redis/DB)
- [ ] Advanced analytics dashboard
- [ ] A/B testing support

---

## Related Documentation

- [COMPRESSION_HASHING.md](COMPRESSION_HASHING.md) - Hash specification
- [COMPRESSION_INFERENCE_INTEGRATION.md](COMPRESSION_INFERENCE_INTEGRATION.md) - Inference integration
- [Tensors.md](Tensors.md) - ELP mathematics

---

## API Reference

See generated docs:
```bash
cargo doc --open --package spatial-vortex
```

Navigate to: `spatialvortex::ai_router`

---

**Status**: Production Ready âœ…  
**Version**: 1.0.0  
**License**: MIT  
**Maintainer**: SpatialVortex Team
